{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "k_means.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H22pUSpSp2BO"
      },
      "source": [
        "3. K-means klastersanje putem MapReduce programa (5 bodova)\r\n",
        "Napisati map/reduce program koji vrši k-means klasterisanje liste vektora. Nasumično generisati podatke iz nekoliko normalnih raspodela u dve dimenzije i pokazati da algoritam radi (videti vežbe za primer). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6x5Psd1-x8j"
      },
      "source": [
        "from functools import reduce, partial\n",
        "import multiprocessing, matplotlib.pyplot as plt, numpy as np, random, math\n",
        "from sklearn.preprocessing import StandardScaler        # Needed for PCA.\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XO-5X5CjIzG"
      },
      "source": [
        "def plot( fig, data, centroids, col_flag = False ):\r\n",
        "    \r\n",
        "    for i, d in enumerate( data ):\r\n",
        "        col_indx = i // nk if col_flag is False else clusters[i]\r\n",
        "        plt.scatter( d[1][0], d[1][1], color = colors[ col_indx ] )\r\n",
        "\r\n",
        "    for i, cent in enumerate( centroids ):\r\n",
        "        if cent is not None:\r\n",
        "            plt.scatter( cent[0], cent[1], 500, marker = 'x', color = colors[i] )\r\n",
        "    \r\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DltDxH1L--qG"
      },
      "source": [
        "nk = 100                        # Number of samples in the cluster.\n",
        "k = 3                           # Number of clusters.\n",
        "N = nk * k\n",
        "n_dim = 2\n",
        "mu, sigma = 500, 50             # Mean and standard deviation.\n",
        "colors = [ 'r', 'g', 'b' ]\n",
        "data = []\n",
        "\n",
        "fig, ax = plt.subplots( figsize = ( 15, 10 ) )\n",
        "\n",
        "indx = 0\n",
        "for i in range( k ):\n",
        "    rnd = random.randint( i * 250, ( i + 1 ) * 250 )\n",
        "\n",
        "    for j in range( nk ):\n",
        "        point = [ np.random.normal( rnd, sigma ) for i in range( n_dim ) ]\n",
        "        data.append( ( indx, np.array( point ) ) )\n",
        "        indx += 1\n",
        "        \n",
        "centroids = [ np.array( data[ random.randint( 0, N ) ][1] ) for i in range( k ) ]\n",
        "\n",
        "plot( fig, data, centroids )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bnQmsQ3Ehxn"
      },
      "source": [
        "def dist( x, y ):\n",
        "    return math.sqrt( sum( ( p - q ) ** 2.0 for p, q in zip( x, y ) ) )\n",
        "\n",
        "def map_calc_dist( point ):\n",
        "    return [ dist( point[1], centroids[i] ) for i in range( k ) ]\n",
        "\n",
        "def reduce_find_closest( acc, x ):\n",
        "    #return acc + [ x.index( min( x ) ) ]\n",
        "    return acc + [ np.argmin( x ) ]\n",
        "\n",
        "def reduce_test( acc, x ):\n",
        "    return acc + x          # acc and x are numpy arrays.\n",
        "\n",
        "def map_test( key, value ):\n",
        "    acc = np.zeros( shape = ( n_dim ) )\n",
        "    return reduce( reduce_test, value, acc ) / len( value )\n",
        "\n",
        "parallel_dict = dict()\n",
        "\n",
        "pool = multiprocessing.Pool( multiprocessing.cpu_count() )\n",
        "clusters = None\n",
        "\n",
        "for i in range( 5 ):\n",
        "\n",
        "    # This is parallel.\n",
        "    cent_dists = list( map( map_calc_dist, data ) )\n",
        "    clusters = reduce( reduce_find_closest, cent_dists, [] )\n",
        "\n",
        "    # Preparing data for parallel processing.\n",
        "    for i in range( k ):\n",
        "        parallel_dict[i] = list()\n",
        "\n",
        "    for i in range( N ):\n",
        "        cluster_number = clusters[i]\n",
        "        parallel_dict[ cluster_number ].append( data[i][1] )\n",
        "\n",
        "    centroids = list( pool.starmap( map_test, parallel_dict.items() ) )\n",
        "    print( centroids )\n",
        "\n",
        "pool.terminate()\n",
        "\n",
        "fig, ax = plt.subplots( figsize = ( 20, 10 ) )\n",
        "\n",
        "plot( fig, data, centroids, col_flag = True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTIxJxqVc83E"
      },
      "source": [
        "final_dict = dict()\r\n",
        "\r\n",
        "for i in range( k ):\r\n",
        "        final_dict[i] = list()\r\n",
        "\r\n",
        "for i in range( N ):\r\n",
        "    final_dict[ clusters[i] ].append( i )\r\n",
        "\r\n",
        "for key, value in final_dict.items():\r\n",
        "    print( key, ' -> ', value )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}